# PIPELINE DEFINITION
# Name: breast-cancer-classification
# Description: A pipeline that process and learns from images of the curated_breast_imaging_ddsm dataset
# Inputs:
#    batch_size: int [Default: 4.0]
#    eval_every: int [Default: 200.0]
#    learning_rate: float [Default: 0.005]
#    momentum: float [Default: 0.9]
#    train_steps: int [Default: 1200.0]
components:
  comp-create-tf-records:
    executorLabel: exec-create-tf-records
    inputDefinitions:
      artifacts:
        dataset:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
      parameters:
        base_output_directory:
          defaultValue: ''
          isOptional: true
          parameterType: STRING
        display_name:
          defaultValue: Create TF Records
          isOptional: true
          parameterType: STRING
        enable_web_access:
          defaultValue: false
          isOptional: true
          parameterType: BOOLEAN
        encryption_spec_key_name:
          defaultValue: ''
          isOptional: true
          parameterType: STRING
        labels:
          defaultValue: {}
          isOptional: true
          parameterType: STRUCT
        location:
          defaultValue: us-central1
          isOptional: true
          parameterType: STRING
        network:
          defaultValue: ''
          isOptional: true
          parameterType: STRING
        persistent_resource_id:
          defaultValue: '{{$.pipeline_persistent_resource_id}}'
          isOptional: true
          parameterType: STRING
        project:
          defaultValue: '{{$.pipeline_google_cloud_project_id}}'
          isOptional: true
          parameterType: STRING
        reserved_ip_ranges:
          defaultValue: []
          isOptional: true
          parameterType: LIST
        restart_job_on_worker_restart:
          defaultValue: false
          isOptional: true
          parameterType: BOOLEAN
        service_account:
          defaultValue: ''
          isOptional: true
          parameterType: STRING
        tensorboard:
          defaultValue: ''
          isOptional: true
          parameterType: STRING
        timeout:
          defaultValue: 604800s
          isOptional: true
          parameterType: STRING
        worker_pool_specs:
          defaultValue:
          - container_spec:
              args:
              - --executor_input
              - '{{$.json_escape[1]}}'
              - --function_to_execute
              - create_tf_records
              command:
              - sh
              - -c
              - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip\
                \ || python3 -m ensurepip --user || apt-get install python3-pip\n\
                fi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet\
                \ --no-warn-script-location 'kfp==2.7.0' '--no-deps' 'typing-extensions>=3.7.4,<5;\
                \ python_version<\"3.9\"'  &&  python3 -m pip install --quiet --no-warn-script-location\
                \ 'tensorflow-datasets==4.9.6' 'opencv-python-headless==4.10.0.84'\
                \ 'tensorflow==2.17.0' && \"$0\" \"$@\"\n"
              - sh
              - -ec
              - 'program_path=$(mktemp -d)


                printf "%s" "$0" > "$program_path/ephemeral_component.py"

                _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

                '
              - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing\
                \ import *\n\ndef create_tf_records(\n    dataset: Input[Artifact],\n\
                \    tf_records: Output[Artifact],\n):\n    import os\n    import\
                \ tarfile\n\n    import tensorflow_datasets as tfds\n\n    with tarfile.open(dataset.path)\
                \ as tar:\n        # Extract all contents to the specified directory\n\
                \        tar.extractall(path=\"./extracted_dataset\")\n    curated_breast_imaging_ddsm\
                \ = tfds.builder(\"curated_breast_imaging_ddsm\")\n    curated_breast_imaging_ddsm.download_and_prepare(\n\
                \        download_config=tfds.download.DownloadConfig(manual_dir=\"\
                ./extracted_dataset\")\n    )\n    datasets = curated_breast_imaging_ddsm.as_dataset()\n\
                \    # ~/tensorflow_datasets/curated_breast_imaging_ddsm/patches/3.0.0\n\
                \    folder_path = os.path.join(\n        os.path.expanduser(\"~\"\
                ),\n        \"tensorflow_datasets\",\n        \"curated_breast_imaging_ddsm\"\
                ,\n        \"patches\",\n        \"3.0.0\",\n    )\n    with tarfile.open(tf_records.path,\
                \ \"w\") as tar:\n        tar.add(folder_path, arcname=os.path.basename(folder_path))\n\
                \n"
              env: []
              image_uri: python:3.12
            disk_spec:
              boot_disk_size_gb: 600.0
              boot_disk_type: pd-ssd
            machine_spec:
              machine_type: n1-standard-4
            replica_count: 1.0
          isOptional: true
          parameterType: LIST
    outputDefinitions:
      artifacts:
        tf_records:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
      parameters:
        gcp_resources:
          parameterType: STRING
  comp-download-dataset:
    executorLabel: exec-download-dataset
    inputDefinitions:
      parameters:
        base_output_directory:
          defaultValue: ''
          isOptional: true
          parameterType: STRING
        display_name:
          defaultValue: Download Dataset
          isOptional: true
          parameterType: STRING
        enable_web_access:
          defaultValue: false
          isOptional: true
          parameterType: BOOLEAN
        encryption_spec_key_name:
          defaultValue: ''
          isOptional: true
          parameterType: STRING
        labels:
          defaultValue: {}
          isOptional: true
          parameterType: STRUCT
        location:
          defaultValue: us-central1
          isOptional: true
          parameterType: STRING
        network:
          defaultValue: ''
          isOptional: true
          parameterType: STRING
        persistent_resource_id:
          defaultValue: '{{$.pipeline_persistent_resource_id}}'
          isOptional: true
          parameterType: STRING
        project:
          defaultValue: '{{$.pipeline_google_cloud_project_id}}'
          isOptional: true
          parameterType: STRING
        reserved_ip_ranges:
          defaultValue: []
          isOptional: true
          parameterType: LIST
        restart_job_on_worker_restart:
          defaultValue: false
          isOptional: true
          parameterType: BOOLEAN
        service_account:
          defaultValue: ''
          isOptional: true
          parameterType: STRING
        tensorboard:
          defaultValue: ''
          isOptional: true
          parameterType: STRING
        timeout:
          defaultValue: 604800s
          isOptional: true
          parameterType: STRING
        worker_pool_specs:
          defaultValue:
          - container_spec:
              args:
              - --output
              - '{{$.outputs.artifacts[''dataset''].path}}'
              command:
              - python
              - setup.py
              env: []
              image_uri: davidnet/cbis_ddsm_dataloader:1.0.2
            disk_spec:
              boot_disk_size_gb: 600.0
              boot_disk_type: pd-ssd
            machine_spec:
              machine_type: n1-standard-4
            replica_count: 1.0
          isOptional: true
          parameterType: LIST
    outputDefinitions:
      artifacts:
        dataset:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
      parameters:
        gcp_resources:
          parameterType: STRING
  comp-train:
    executorLabel: exec-train
    inputDefinitions:
      artifacts:
        tf_records:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
      parameters:
        base_output_directory:
          defaultValue: ''
          isOptional: true
          parameterType: STRING
        batch_size:
          parameterType: NUMBER_INTEGER
        display_name:
          defaultValue: Train Model
          isOptional: true
          parameterType: STRING
        enable_web_access:
          defaultValue: false
          isOptional: true
          parameterType: BOOLEAN
        encryption_spec_key_name:
          defaultValue: ''
          isOptional: true
          parameterType: STRING
        eval_every:
          parameterType: NUMBER_INTEGER
        labels:
          defaultValue: {}
          isOptional: true
          parameterType: STRUCT
        learning_rate:
          parameterType: NUMBER_DOUBLE
        location:
          defaultValue: us-central1
          isOptional: true
          parameterType: STRING
        momentum:
          parameterType: NUMBER_DOUBLE
        network:
          defaultValue: ''
          isOptional: true
          parameterType: STRING
        persistent_resource_id:
          defaultValue: '{{$.pipeline_persistent_resource_id}}'
          isOptional: true
          parameterType: STRING
        project:
          defaultValue: '{{$.pipeline_google_cloud_project_id}}'
          isOptional: true
          parameterType: STRING
        reserved_ip_ranges:
          defaultValue: []
          isOptional: true
          parameterType: LIST
        restart_job_on_worker_restart:
          defaultValue: false
          isOptional: true
          parameterType: BOOLEAN
        service_account:
          defaultValue: ''
          isOptional: true
          parameterType: STRING
        tensorboard:
          defaultValue: ''
          isOptional: true
          parameterType: STRING
        timeout:
          defaultValue: 604800s
          isOptional: true
          parameterType: STRING
        train_steps:
          parameterType: NUMBER_INTEGER
        worker_pool_specs:
          defaultValue:
          - container_spec:
              args:
              - --train-steps
              - '{{$.inputs.parameters[''train_steps'']}}'
              - --eval-every
              - '{{$.inputs.parameters[''eval_every'']}}'
              - --batch-size
              - '{{$.inputs.parameters[''batch_size'']}}'
              - --learning-rate
              - '{{$.inputs.parameters[''learning_rate'']}}'
              - --momentum
              - '{{$.inputs.parameters[''momentum'']}}'
              - --output
              - '{{$.outputs.artifacts[''checkpoints''].path}}'
              - --tfrecords
              - '{{$.inputs.artifacts[''tf_records''].path}}'
              command:
              - python
              - train.py
              env: []
              image_uri: davidnet/flax-cnn-model:1.0.0
            disk_spec:
              boot_disk_size_gb: 600.0
              boot_disk_type: pd-ssd
            machine_spec:
              accelerator_count: 1.0
              accelerator_type: NVIDIA_TESLA_T4
              machine_type: n1-standard-4
            replica_count: 1.0
          isOptional: true
          parameterType: LIST
    outputDefinitions:
      artifacts:
        checkpoints:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
      parameters:
        gcp_resources:
          parameterType: STRING
deploymentSpec:
  executors:
    exec-create-tf-records:
      container:
        args:
        - --type
        - CustomJob
        - --payload
        - '{"display_name": "{{$.inputs.parameters[''display_name'']}}", "job_spec":
          {"worker_pool_specs": {{$.inputs.parameters[''worker_pool_specs'']}}, "scheduling":
          {"timeout": "{{$.inputs.parameters[''timeout'']}}", "restart_job_on_worker_restart":
          {{$.inputs.parameters[''restart_job_on_worker_restart'']}}}, "service_account":
          "{{$.inputs.parameters[''service_account'']}}", "tensorboard": "{{$.inputs.parameters[''tensorboard'']}}",
          "enable_web_access": {{$.inputs.parameters[''enable_web_access'']}}, "network":
          "{{$.inputs.parameters[''network'']}}", "reserved_ip_ranges": {{$.inputs.parameters[''reserved_ip_ranges'']}},
          "base_output_directory": {"output_uri_prefix": "{{$.inputs.parameters[''base_output_directory'']}}"},
          "persistent_resource_id": "{{$.inputs.parameters[''persistent_resource_id'']}}"},
          "labels": {{$.inputs.parameters[''labels'']}}, "encryption_spec": {"kms_key_name":
          "{{$.inputs.parameters[''encryption_spec_key_name'']}}"}}'
        - --project
        - '{{$.inputs.parameters[''project'']}}'
        - --location
        - '{{$.inputs.parameters[''location'']}}'
        - --gcp_resources
        - '{{$.outputs.parameters[''gcp_resources''].output_file}}'
        command:
        - python3
        - -u
        - -m
        - google_cloud_pipeline_components.container.v1.custom_job.launcher
        image: gcr.io/ml-pipeline/google-cloud-pipeline-components:2.17.0
    exec-download-dataset:
      container:
        args:
        - --type
        - CustomJob
        - --payload
        - '{"display_name": "{{$.inputs.parameters[''display_name'']}}", "job_spec":
          {"worker_pool_specs": {{$.inputs.parameters[''worker_pool_specs'']}}, "scheduling":
          {"timeout": "{{$.inputs.parameters[''timeout'']}}", "restart_job_on_worker_restart":
          {{$.inputs.parameters[''restart_job_on_worker_restart'']}}}, "service_account":
          "{{$.inputs.parameters[''service_account'']}}", "tensorboard": "{{$.inputs.parameters[''tensorboard'']}}",
          "enable_web_access": {{$.inputs.parameters[''enable_web_access'']}}, "network":
          "{{$.inputs.parameters[''network'']}}", "reserved_ip_ranges": {{$.inputs.parameters[''reserved_ip_ranges'']}},
          "base_output_directory": {"output_uri_prefix": "{{$.inputs.parameters[''base_output_directory'']}}"},
          "persistent_resource_id": "{{$.inputs.parameters[''persistent_resource_id'']}}"},
          "labels": {{$.inputs.parameters[''labels'']}}, "encryption_spec": {"kms_key_name":
          "{{$.inputs.parameters[''encryption_spec_key_name'']}}"}}'
        - --project
        - '{{$.inputs.parameters[''project'']}}'
        - --location
        - '{{$.inputs.parameters[''location'']}}'
        - --gcp_resources
        - '{{$.outputs.parameters[''gcp_resources''].output_file}}'
        command:
        - python3
        - -u
        - -m
        - google_cloud_pipeline_components.container.v1.custom_job.launcher
        image: gcr.io/ml-pipeline/google-cloud-pipeline-components:2.17.0
    exec-train:
      container:
        args:
        - --type
        - CustomJob
        - --payload
        - '{"display_name": "{{$.inputs.parameters[''display_name'']}}", "job_spec":
          {"worker_pool_specs": {{$.inputs.parameters[''worker_pool_specs'']}}, "scheduling":
          {"timeout": "{{$.inputs.parameters[''timeout'']}}", "restart_job_on_worker_restart":
          {{$.inputs.parameters[''restart_job_on_worker_restart'']}}}, "service_account":
          "{{$.inputs.parameters[''service_account'']}}", "tensorboard": "{{$.inputs.parameters[''tensorboard'']}}",
          "enable_web_access": {{$.inputs.parameters[''enable_web_access'']}}, "network":
          "{{$.inputs.parameters[''network'']}}", "reserved_ip_ranges": {{$.inputs.parameters[''reserved_ip_ranges'']}},
          "base_output_directory": {"output_uri_prefix": "{{$.inputs.parameters[''base_output_directory'']}}"},
          "persistent_resource_id": "{{$.inputs.parameters[''persistent_resource_id'']}}"},
          "labels": {{$.inputs.parameters[''labels'']}}, "encryption_spec": {"kms_key_name":
          "{{$.inputs.parameters[''encryption_spec_key_name'']}}"}}'
        - --project
        - '{{$.inputs.parameters[''project'']}}'
        - --location
        - '{{$.inputs.parameters[''location'']}}'
        - --gcp_resources
        - '{{$.outputs.parameters[''gcp_resources''].output_file}}'
        command:
        - python3
        - -u
        - -m
        - google_cloud_pipeline_components.container.v1.custom_job.launcher
        image: gcr.io/ml-pipeline/google-cloud-pipeline-components:2.17.0
pipelineInfo:
  description: A pipeline that process and learns from images of the curated_breast_imaging_ddsm
    dataset
  displayName: Breast Cancer Classification
  name: breast-cancer-classification
root:
  dag:
    tasks:
      create-tf-records:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-create-tf-records
        dependentTasks:
        - download-dataset
        inputs:
          artifacts:
            dataset:
              taskOutputArtifact:
                outputArtifactKey: dataset
                producerTask: download-dataset
        taskInfo:
          name: create-tf-records
      download-dataset:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-download-dataset
        taskInfo:
          name: download-dataset
      train:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-train
        dependentTasks:
        - create-tf-records
        inputs:
          artifacts:
            tf_records:
              taskOutputArtifact:
                outputArtifactKey: tf_records
                producerTask: create-tf-records
          parameters:
            batch_size:
              componentInputParameter: batch_size
            eval_every:
              componentInputParameter: eval_every
            learning_rate:
              componentInputParameter: learning_rate
            momentum:
              componentInputParameter: momentum
            train_steps:
              componentInputParameter: train_steps
        taskInfo:
          name: train
  inputDefinitions:
    parameters:
      batch_size:
        defaultValue: 4.0
        isOptional: true
        parameterType: NUMBER_INTEGER
      eval_every:
        defaultValue: 200.0
        isOptional: true
        parameterType: NUMBER_INTEGER
      learning_rate:
        defaultValue: 0.005
        isOptional: true
        parameterType: NUMBER_DOUBLE
      momentum:
        defaultValue: 0.9
        isOptional: true
        parameterType: NUMBER_DOUBLE
      train_steps:
        defaultValue: 1200.0
        isOptional: true
        parameterType: NUMBER_INTEGER
schemaVersion: 2.1.0
sdkVersion: kfp-2.7.0
